{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a High-Skip Network (HSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from toponetx import SimplicialComplex\n",
    "from topomodelx.nn.simplicial.hsn_layer import HSNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create signal and domain\n",
    "\n",
    "The first step is to define the topological domain on which the TNN will operate, as well as the neighborhod structures characterizing this domain. We will only define th eneighborhood matrices that we plan on using.\n",
    "\n",
    "Here, we build a simple simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplexView([(1,), (2,), (3,), (1, 2), (1, 3)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_set = [[1, 2], [1, 3]]\n",
    "\n",
    "domain = SimplicialComplex(edge_set)\n",
    "domain.simplices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve the boundary matrix (or incidence matrix) associated to the faces of this complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incidence_1\n",
      " [[-1. -1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "adjacency_0\n",
      " [[0. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "incidence_1 = domain.incidence_matrix(rank=1)\n",
    "adjacency_0 = domain.adjacency_matrix(rank=0)\n",
    "\n",
    "print(\"incidence_1\\n\", incidence_1.todense())\n",
    "print(\"adjacency_0\\n\", adjacency_0.todense())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rank, the signal on this domain will look like a matrix with shape n_cells_of_rank_r x in_channels, where in_channels is the dimension of each cell's feature. In a a heterogenous domain, in_channels will vary by rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nodes = torch.tensor([[1.0, 1.0], [2.0, 2.0], [1.0, 1.0]])\n",
    "channels_nodes = x_nodes.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network\n",
    "\n",
    "Stack layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSN(torch.nn.Module):\n",
    "    def __init__(self, channels, incidence_matrix_1, adjacency_matrix_0, n_layers=2):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        for _ in range(n_layers):\n",
    "            modules.append(\n",
    "                HSNLayer(\n",
    "                    channels=channels,\n",
    "                    incidence_matrix_1=incidence_matrix_1,\n",
    "                    adjacency_matrix_0=adjacency_matrix_0,\n",
    "                )\n",
    "            )\n",
    "        self.sequential = torch.nn.Sequential(*modules)\n",
    "        self.linear = torch.nn.Linear(channels, 1)\n",
    "\n",
    "    def forward(self, x_nodes):\n",
    "        x_nodes = self.sequential(x_nodes)\n",
    "        return self.linear(x_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "Specify the model, assign ground truth labels for a classification task, and specify optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathildepapillon/opt/anaconda3/envs/tmx/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = HSN(\n",
    "    channels=channels_nodes,\n",
    "    incidence_matrix_1=incidence_1,\n",
    "    adjacency_matrix_0=adjacency_0,\n",
    "    n_layers=2,\n",
    ")\n",
    "nodes_gt_labels = torch.Tensor([[0], [1], [1]])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    nodes_pred_labels = model(x_nodes)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        nodes_pred_labels, nodes_gt_labels\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
