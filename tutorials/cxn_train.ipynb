{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Set-up, create and train a convolutional CXN\n",
    "\n",
    "In this notebook, we create and train a CXN network, originally proposed in the paper by Hajij et. al : Cell Complex Neural Networks (https://arxiv.org/pdf/2010.00743.pdf). We will load a cell complex dataset from the web and train the model to perform classificaiton on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "from toponetx import CellComplex\n",
    "\n",
    "from topomodelx.nn.cell.cxn_layer import CXNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\", default=1e-3, type=float)\n",
    "parser.add_argument(\"--num_epochs\", default=3, type=int)\n",
    "parser.add_argument(\"--with_rotation\", default=1, type=int, choices=[0, 1])\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "training_cfg = {\n",
    "    \"lr\": args.lr,\n",
    "    \"num_epochs\": args.num_epochs,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Create synthetic data and load its neighborhood structures\n",
    "\n",
    "We start by creating the cell complex on which the neural network will operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complex with 6 nodes, 8 edges  and 1 2-cells \n",
      "8\n"
     ]
    }
   ],
   "source": [
    "edge_set = [\n",
    "    [1, 2],\n",
    "    [1, 3],\n",
    "    [2, 4],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [1, 6],\n",
    "]  # two edges stick out on diag\n",
    "node_set = [1, 2, 3, 4, 5, 6]\n",
    "face_set = [[1, 2, 3, 4]]\n",
    "complex = CellComplex(edge_set + node_set + face_set)\n",
    "print(complex)\n",
    "print(len(complex.edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "incidence_2_t = complex.incidence_matrix(rank=2).T\n",
    "adjacency_0 = complex.adjacency_matrix(rank=0)\n",
    "incidence_2_t = torch.from_numpy(incidence_2_t.todense()).to_sparse().float()\n",
    "adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse().float()\n",
    "print(adjacency_0.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create data on this complex. Specifically, we need node features and edge features for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_train = []\n",
    "num_features_0 = 4\n",
    "for _ in range(100):\n",
    "    x_0_train.append(torch.Tensor(np.random.rand(len(complex.nodes), num_features_0)))\n",
    "\n",
    "x_1_train = []\n",
    "num_features_1 = 5\n",
    "for _ in range(100):\n",
    "    x_1_train.append(torch.Tensor(np.random.rand(len(complex.edges), num_features_1)))\n",
    "\n",
    "x_0_test = []\n",
    "num_features_0 = 4\n",
    "for _ in range(10):\n",
    "    x_0_test.append(torch.Tensor(np.random.rand(len(complex.nodes), num_features_0)))\n",
    "\n",
    "x_1_test = []\n",
    "num_features_1 = 5\n",
    "for _ in range(10):\n",
    "    x_1_test.append(torch.Tensor(np.random.rand(len(complex.edges), num_features_1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must define labels associated to these datasets, as we will perform binary node classification. For the purposes of the tutorial, we leave these completely random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [random.randint(0, 1) for _ in range(100)]\n",
    "labels_test = [random.randint(0, 1) for _ in range(10)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the input feature dimensions as channel dimensions. We will use this to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_ch_v 4 in_ch_e 5 in_ch_f 5\n"
     ]
    }
   ],
   "source": [
    "in_ch_0 = num_features_0\n",
    "in_ch_1 = num_features_1\n",
    "in_ch_2 = 5\n",
    "print(f\"in_ch_v {in_ch_0} in_ch_e {in_ch_1} in_ch_f {in_ch_2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CXNLayer class, we create a neural network with stacked layers. We define the amount of channels on the face and edge ranks to be different, making this a heterogenous network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CXN(torch.nn.Module):\n",
    "    \"\"\"Convolutional CXN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_ch_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_ch_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_ch_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CXN layers.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch_0, in_ch_1, in_ch_2, num_classes, n_layers=2, att=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                CXNLayer(\n",
    "                    in_channels_0=in_ch_0,\n",
    "                    in_channels_1=in_ch_1,\n",
    "                    in_channels_2=in_ch_2,\n",
    "                    att=att,\n",
    "                )\n",
    "            )\n",
    "        self.layers = layers\n",
    "        self.lin_0 = torch.nn.Linear(in_ch_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_ch_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_ch_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2):\n",
    "        \"\"\"Forward computation through CXN layers then linear layers.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "        return torch.mean(x_2, dim=0) + torch.mean(x_1, dim=0) + torch.mean(x_0, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CXN(in_ch_0, in_ch_1, in_ch_2, num_classes=2, n_layers=2)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for 5 epochs and testing after every 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 5.1707 Train_acc: 0.4900\n",
      "Epoch: 2 loss: 2.7265 Train_acc: 0.4900\n",
      "Test_acc: 0.6000\n",
      "Epoch: 3 loss: 1.0470 Train_acc: 0.5200\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, args.num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, y in zip(x_0_train, x_1_train, labels_train):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_hat = model(\n",
    "            x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "        )\n",
    "        y = torch.tensor(y).long()\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, y in zip(x_0_test, x_1_test, labels_test):\n",
    "                y = torch.tensor(y).long()\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new neural network, that uses the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CXN(in_ch_0, in_ch_1, in_ch_2, num_classes=2, n_layers=2, att=True)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the training for this neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[6, 6]' is invalid for input of size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m x_0, x_1, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x_0_train, x_1_train, labels_train):\n\u001b[1;32m      9\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     y_hat \u001b[39m=\u001b[39m model(\n\u001b[1;32m     12\u001b[0m         x_0\u001b[39m.\u001b[39;49mfloat(), x_1\u001b[39m.\u001b[39;49mfloat(), adjacency_0\u001b[39m.\u001b[39;49mfloat(), incidence_2_t\u001b[39m.\u001b[39;49mfloat()\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     15\u001b[0m     loss \u001b[39m=\u001b[39m crit(y_hat, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/topomodelx310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m, in \u001b[0;36mCXN.forward\u001b[0;34m(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward computation through CXN layers then linear layers.\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 40\u001b[0m     x_0, x_1, x_2 \u001b[39m=\u001b[39m layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n\u001b[1;32m     41\u001b[0m x_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_0(x_0)\n\u001b[1;32m     42\u001b[0m x_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_1(x_1)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/topomodelx310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/GoogleDrive/My Drive/code/TopoModelX/topomodelx/nn/cell/cxn_layer.py:58\u001b[0m, in \u001b[0;36mCXNLayer.forward\u001b[0;34m(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\u001b[0m\n\u001b[1;32m     55\u001b[0m x_0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(x_0)\n\u001b[1;32m     56\u001b[0m x_1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(x_1)\n\u001b[0;32m---> 58\u001b[0m x_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_0_to_0(x_0, neighborhood_0_to_0)\n\u001b[1;32m     59\u001b[0m x_0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(x_0)\n\u001b[1;32m     61\u001b[0m x_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_1_to_2(x_1, neighborhood_1_to_2)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/topomodelx310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/GoogleDrive/My Drive/code/TopoModelX/topomodelx/base/conv.py:95\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x, neighborhood)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_index_i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_index_j \u001b[39m=\u001b[39m neighborhood\u001b[39m.\u001b[39mindices()\n\u001b[1;32m     94\u001b[0m     attention_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(x)\n\u001b[0;32m---> 95\u001b[0m     attention \u001b[39m=\u001b[39m attention_values\u001b[39m.\u001b[39;49mview(\u001b[39m*\u001b[39;49mneighborhood\u001b[39m.\u001b[39;49mshape)\u001b[39m.\u001b[39mto_sparse()\n\u001b[1;32m     96\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n\u001b[1;32m     97\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(neighborhood, x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[6, 6]' is invalid for input of size 16"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, args.num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, y in zip(x_0_train, x_1_train, labels_train):\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_hat = model(\n",
    "            x_0.float(), x_1.float(), adjacency_0.float(), incidence_2_t.float()\n",
    "        )\n",
    "        y = torch.tensor(y).long()\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, y in zip(x_0_test, x_1_test, labels_test):\n",
    "                y = torch.tensor(y).long()\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
