{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial 2-complex convolutional neural network (SCConv)\n",
    "\n",
    "\n",
    "In this notebook, we will create and train a Simplicial 2-complex convolutional neural in the simplicial complex domain, as proposed in the paper by [Bunch et. al : Simplicial 2-Complex Convolutional Neural Networks (2020)](https://openreview.net/pdf?id=Sc8glB-k6e9).\n",
    "\n",
    "\n",
    "We train the model to perform\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "游린 $\\quad m_{y\\rightarrow x}^{(0\\rightarrow 0)} = ({\\tilde{A}_{\\uparrow,0}})_{xy} \\cdot h_y^{t,(0)} \\cdot \\Theta^{t,(0\\rightarrow0)}$\n",
    "\n",
    "游린 $\\quad m^{(1\\rightarrow0)}_{y\\rightarrow x}  = (B_1)_{xy} \\cdot h_y^{t,(0)} \\cdot \\Theta^{t,(1\\rightarrow 0)}$\n",
    "\n",
    "游린 $\\quad m^{(0 \\rightarrow 1)}_{y \\rightarrow x}  = (\\tilde B_1)_{xy} \\cdot h_y^{t,(0)} \\cdot \\Theta^{t,(0 \\rightarrow1)}$\n",
    "\n",
    "游린 $\\quad m^{(1\\rightarrow1)}_{y\\rightarrow x} = ({\\tilde{A}_{\\downarrow,1}} + {\\tilde{A}_{\\uparrow,1}})_{xy} \\cdot h_y^{t,(1)} \\cdot \\Theta^{t,(1\\rightarrow1)}$\n",
    "\n",
    "游린 $\\quad m^{(2\\rightarrow1)}_{y \\rightarrow x}  = (B_2)_{xy} \\cdot h_y^{t,(2)} \\cdot \\Theta^{t,(2 \\rightarrow1)}$\n",
    "\n",
    "游린 $\\quad m^{(1 \\rightarrow 2)}_{y \\rightarrow x}  = (\\tilde B_2)_{xy} \\cdot h_y^{t,(1)} \\cdot \\Theta^{t,(1 \\rightarrow 2)}$\n",
    "\n",
    "游린 $\\quad m^{(2 \\rightarrow 2)}_{y \\rightarrow x}  = ({\\tilde{A}_{\\downarrow,2}})\\_{xy} \\cdot h_y^{t,(2)} \\cdot \\Theta^{t,(2 \\rightarrow 2)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 0)}  = \\sum_{y \\in \\mathcal{L}_\\uparrow(x)} m_{y \\rightarrow x}^{(0 \\rightarrow 0)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(1 \\rightarrow 0)}  = \\sum_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(1 \\rightarrow 0)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1)}  = \\sum_{y \\in \\mathcal{B}(x)} m_{y \\rightarrow x}^{(0 \\rightarrow 1)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(1 \\rightarrow 1)}  = \\sum_{y \\in (\\mathcal{L}_\\uparrow(x) + \\mathcal{L}_\\downarrow(x))} m_{y \\rightarrow x}^{(1 \\rightarrow 1)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(2 \\rightarrow 1)} = \\sum_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(2 \\rightarrow 1)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(1 \\rightarrow 2)}  = \\sum_{y \\in \\mathcal{B}(x)} m_{y \\rightarrow x}^{(1 \\rightarrow 2)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(2 \\rightarrow 2)}  = \\sum_{y \\in \\mathcal{L}_\\downarrow(x)} m_{y \\rightarrow x}^{(2 \\rightarrow 2)}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}  = m_x^{(1\\rightarrow0)}+ m_x^{(0\\rightarrow0)}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}  = m_x^{(2\\rightarrow1)}+ m_x^{(1\\rightarrow1)}$\n",
    "\n",
    "游릱 $\\quad h^{t+1, (0)}_x  = \\sigma(m_x^{(0)})$\n",
    "\n",
    "游릱 $\\quad h^{t+1, (1)}_x  = \\sigma(m_x^{(1)})$\n",
    "\n",
    "游릱 $\\quad h^{t+1, (2)}_x  = \\sigma(m_x^{(2)})$\n",
    "\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets.graph as graph\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import diags\n",
    "\n",
    "\n",
    "# from topomodelx.nn.simplicial.scconv_layer import SCConvLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "The first step is to import the dataset, shrec 16, a benchmark dataset for 3D mesh classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T04:25:01.902814606Z",
     "start_time": "2023-06-26T04:25:00.067431655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 0th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 0th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 0\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:25:05.161535039Z",
     "start_time": "2023-06-26T04:25:05.142961595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 29)\t1.0\n",
      "  (0, 3)\t-1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 1)\t-1.0\n",
      "  (0, 0)\t2.0\n",
      "  (1, 34)\t1.0\n",
      "  (1, 2)\t-1.0\n",
      "  (1, 28)\t-1.0\n",
      "  (1, 1)\t2.0\n",
      "  (1, 0)\t-1.0\n",
      "  (2, 63)\t1.0\n",
      "  (2, 4)\t-1.0\n",
      "  (2, 34)\t-1.0\n",
      "  (2, 2)\t2.0\n",
      "  (2, 1)\t-1.0\n",
      "  (3, 72)\t1.0\n",
      "  (3, 4)\t-1.0\n",
      "  (3, 29)\t-1.0\n",
      "  (3, 3)\t2.0\n",
      "  (3, 0)\t-1.0\n",
      "  (4, 72)\t-1.0\n",
      "  (4, 3)\t-1.0\n",
      "  (4, 63)\t-1.0\n",
      "  (4, 4)\t2.0\n",
      "  (4, 2)\t-1.0\n",
      "  :\t:\n",
      "  (745, 746)\t-1.0\n",
      "  (745, 744)\t-1.0\n",
      "  (745, 745)\t2.0\n",
      "  (745, 732)\t-1.0\n",
      "  (745, 731)\t1.0\n",
      "  (746, 748)\t1.0\n",
      "  (746, 747)\t-1.0\n",
      "  (746, 746)\t2.0\n",
      "  (746, 745)\t-1.0\n",
      "  (746, 744)\t1.0\n",
      "  (747, 748)\t-1.0\n",
      "  (747, 746)\t-1.0\n",
      "  (747, 747)\t2.0\n",
      "  (747, 711)\t-1.0\n",
      "  (747, 709)\t1.0\n",
      "  (748, 747)\t-1.0\n",
      "  (748, 746)\t1.0\n",
      "  (748, 748)\t2.0\n",
      "  (748, 729)\t-1.0\n",
      "  (748, 727)\t1.0\n",
      "  (749, 729)\t-1.0\n",
      "  (749, 728)\t1.0\n",
      "  (749, 749)\t2.0\n",
      "  (749, 711)\t-1.0\n",
      "  (749, 710)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#for s in simplexes:\n",
    "print(simplexes[13].up_laplacian_matrix(rank=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:25:07.369913355Z",
     "start_time": "2023-06-26T04:25:07.361167935Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the boundary matrix (or incidence matrix) $B_1$ and the adjacency matrix $A_{\\uparrow,0}$ on the nodes. For a santiy check, we show that the shape of the $B_1 = n_\\text{nodes} \\times n_\\text{edges}$ and $A_{\\uparrow,0} = n_\\text{nodes} \\times n_\\text{nodes}$. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def normalize_higher_order_adj(A_opt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        A_opt is an opt that maps a j-cochain to a k-cochain.\n",
    "        shape [num_of_k_simplices num_of_j_simplices]\n",
    "\n",
    "    return:\n",
    "         D^{-0.5}* (A_opt)* D^{-0.5}.\n",
    "    \"\"\"\n",
    "    rowsum = np.array(np.abs(A_opt).sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.0\n",
    "    r_mat_inv_sqrt = diags(r_inv_sqrt)\n",
    "    A_opt_to = A_opt.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "    return coo_matrix(A_opt_to)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_neighborhoods(simplexes):\n",
    "    B1_list = []\n",
    "    B2_list = []\n",
    "    up_laplacian_1_list = []\n",
    "    up_laplacian_2_list = []\n",
    "    down_laplacian_1_list = []\n",
    "    down_laplacian_2_list = []\n",
    "    for simplex in simplexes:\n",
    "        B1 = simplex.incidence_matrix(rank=1, signed=False)\n",
    "        B2 = simplex.incidence_matrix(rank=2, signed=False)\n",
    "\n",
    "        up_laplacian_1 = simplex.up_laplacian_matrix(rank=0) #1\n",
    "        up_laplacian_2 = simplex.up_laplacian_matrix(rank=1) #2\n",
    "\n",
    "        down_laplacian_1 = simplex.down_laplacian_matrix(rank=1) #1\n",
    "        down_laplacian_2 = simplex.down_laplacian_matrix(rank=2) #2\n",
    "\n",
    "        incidence_1 = torch.from_numpy(B1.todense()).to_sparse()\n",
    "        incidence_2 = torch.from_numpy(B2.todense()).to_sparse()\n",
    "\n",
    "        up_laplacian_1 = torch.from_numpy(up_laplacian_1.todense()).to_sparse()\n",
    "        up_laplacian_2 = torch.from_numpy(up_laplacian_2.todense()).to_sparse()\n",
    "\n",
    "        down_laplacian_1 = torch.from_numpy(down_laplacian_1.todense()).to_sparse()\n",
    "        down_laplacian_2 = torch.from_numpy(down_laplacian_2.todense()).to_sparse()\n",
    "\n",
    "        incidence_1_list.append(incidence_1)\n",
    "        incidence_2_list.append(incidence_2)\n",
    "        up_laplacian_1_list.append(up_laplacian_1)\n",
    "        up_laplacian_2_list.append(up_laplacian_2)\n",
    "        down_laplacian_1_list.append(down_laplacian_1)\n",
    "        down_laplacian_2_list.append(down_laplacian_2)\n",
    "\n",
    "    return incidence_1_list,incidence_2_list, up_laplacian_1_list, up_laplacian_2_list, down_laplacian_1_list, down_laplacian_2_list\n",
    "\n",
    "incidence_1_list,incidence_2_list, up_laplacian_1_list, up_laplacian_2_list, down_laplacian_1_list, down_laplacian_2_list  = get_neighborhoods(simplexes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:27:08.057839443Z",
     "start_time": "2023-06-26T04:27:04.700597756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# incidence_1_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:54:56.698762101Z",
     "start_time": "2023-06-26T04:54:56.690271544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:01:22.267420642Z",
     "start_time": "2023-06-27T06:01:22.224729592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 750)\n",
      "(750, 750)\n"
     ]
    }
   ],
   "source": [
    "adjacency_1 = simplexes[13].adjacency_matrix(rank=1, signed=False)\n",
    "incidence_1 = simplexes[13].incidence_matrix(rank=1, signed=False)\n",
    "\n",
    "# k = normalize_higher_order_adj(adjacency_1)\n",
    "# print(k)\n",
    "\n",
    "print(adjacency_1.todense().shape)\n",
    "k = normalize_higher_order_adj(adjacency_1)\n",
    "print(k.todense().shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import signal ##\n",
    "\n",
    "Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape $n_\\text{nodes} \\times$ in_channels, where in_channels is the dimension of each cell's feature. Here, we have in_channels = channels_nodes $ = 34$. This is because the Karate dataset encodes the identity of each of the 34 nodes as a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:14.158869454Z",
     "start_time": "2023-06-12T06:37:14.152308513Z"
    }
   },
   "outputs": [],
   "source": [
    "x_0 = []\n",
    "for _, v in dataset.get_simplex_attributes(\"node_feat\").items():\n",
    "    x_0.append(v)\n",
    "x_0 = torch.tensor(np.stack(x_0))\n",
    "channels_nodes = x_0.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:19.842652169Z",
     "start_time": "2023-06-12T06:37:19.835889237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 nodes with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_0.shape[0]} nodes with features of dimension {x_0.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load edge features, this is how we would do it (note that we will not use these features for this model, and this serves simply as a demonstration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:23.584428419Z",
     "start_time": "2023-06-12T06:37:23.577500033Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"edge_feat\").items():\n",
    "    x_1.append(v)\n",
    "x_1 = np.stack(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:25.774852096Z",
     "start_time": "2023-06-12T06:37:25.759194381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78 edges with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_1.shape[0]} edges with features of dimension {x_1.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for face features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:31.019510467Z",
     "start_time": "2023-06-12T06:37:30.975136460Z"
    }
   },
   "outputs": [],
   "source": [
    "x_2 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"face_feat\").items():\n",
    "    x_2.append(v)\n",
    "x_2 = np.stack(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:45.928261879Z",
     "start_time": "2023-06-12T06:37:45.920637967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 faces with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_2.shape[0]} faces with features of dimension {x_2.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define binary labels\n",
    "We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.\n",
    "\n",
    "We convert the binary labels into one-hot encoder form, and keep the first four nodes' true labels for the purpose of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:37:50.237089180Z",
     "start_time": "2023-06-12T06:37:50.234423970Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "y_true = np.zeros((34, 2))\n",
    "y_true[:, 0] = y\n",
    "y_true[:, 1] = 1 - y\n",
    "y_test = y_true[-4:]\n",
    "y_train = y_true[:30]\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the HSNLayer class, we create a neural network with stacked layers. A linear layer at the end produces an output with shape $n_\\text{nodes} \\times 2$, so we can compare with our binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:38:03.135594070Z",
     "start_time": "2023-06-12T06:38:03.131589436Z"
    }
   },
   "outputs": [],
   "source": [
    "class HSN(torch.nn.Module):\n",
    "    \"\"\"High Skip Network Implementation for binary node classification.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    channels : int\n",
    "        Dimension of features\n",
    "    n_layers : int\n",
    "        Amount of message passing layers.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                HSNLayer(\n",
    "                    channels=channels,\n",
    "                )\n",
    "            )\n",
    "        self.linear = torch.nn.Linear(channels, 2)\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x_0, incidence_1, adjacency_0):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_0 : tensor\n",
    "            shape = [n_nodes, channels]\n",
    "            Node features.\n",
    "\n",
    "        incidence_1 : tensor\n",
    "            shape = [n_nodes, n_edges]\n",
    "            Boundary matrix of rank 1.\n",
    "\n",
    "        adjacency_0 : tensor\n",
    "            shape = [n_nodes, n_nodes]\n",
    "            Adjacency matrix (up) of rank 0.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [n_nodes, 2]\n",
    "            One-hot labels assigned to nodes.\n",
    "\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0 = layer(x_0, incidence_1, adjacency_0)\n",
    "        logits = self.linear(x_0)\n",
    "        return torch.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T06:38:06.785505392Z",
     "start_time": "2023-06-12T06:38:06.739802193Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HSNLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mHSN\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchannels_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.4\u001B[39m)\n",
      "Cell \u001B[0;32mIn[16], line 18\u001B[0m, in \u001B[0;36mHSN.__init__\u001B[0;34m(self, channels, n_layers)\u001B[0m\n\u001B[1;32m     15\u001B[0m layers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_layers):\n\u001B[1;32m     17\u001B[0m     layers\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m---> 18\u001B[0m         \u001B[43mHSNLayer\u001B[49m(\n\u001B[1;32m     19\u001B[0m             channels\u001B[38;5;241m=\u001B[39mchannels,\n\u001B[1;32m     20\u001B[0m         )\n\u001B[1;32m     21\u001B[0m     )\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mLinear(channels, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m layers\n",
      "\u001B[0;31mNameError\u001B[0m: name 'HSNLayer' is not defined"
     ]
    }
   ],
   "source": [
    "model = HSN(\n",
    "    channels=channels_nodes,\n",
    "    n_layers=10,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7181 Train_acc: 0.5667\n",
      "Epoch: 2 loss: 0.7003 Train_acc: 0.5667\n",
      "Test_acc: 0.0000\n",
      "Epoch: 3 loss: 0.6970 Train_acc: 0.5667\n",
      "Epoch: 4 loss: 0.6908 Train_acc: 0.5667\n",
      "Test_acc: 0.0000\n",
      "Epoch: 5 loss: 0.6825 Train_acc: 0.5667\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 5\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x_0, incidence_1, adjacency_0)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_hat[: len(y_train)].float(), y_train.float()\n",
    "    )\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[-len(y_train) :] == y_train).all(dim=1).float().mean().item()\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = model(x_0, incidence_1, adjacency_0)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[-len(y_test) :], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
